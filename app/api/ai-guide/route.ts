import { NextRequest, NextResponse } from 'next/server'
import OpenAI from 'openai'

/**
 * AI ê°€ì´ë“œ ì±„íŒ… API
 * OpenAI GPTë¥¼ í™œìš©í•˜ì—¬ ê²½ì£¼ ê´€ê´‘ ê°€ì´ë“œ ì—­í• ì„ ìˆ˜í–‰
 * 
 * @param request - ì‚¬ìš©ì ë©”ì‹œì§€ì™€ ëŒ€í™” íˆìŠ¤í† ë¦¬ë¥¼ í¬í•¨í•œ POST ìš”ì²­
 * @returns AI ê°€ì´ë“œì˜ ì‘ë‹µ ë©”ì‹œì§€
 */
export async function POST(request: NextRequest) {
  try {
    const { message, conversationHistory = [], language = 'ko' } = await request.json()

    if (!message) {
      return NextResponse.json(
        { error: 'ë©”ì‹œì§€ê°€ í•„ìš”í•©ë‹ˆë‹¤.' },
        { status: 400 }
      )
    }

    // OpenAI API í‚¤ í™•ì¸
    const OPENAI_API_KEY = process.env.OPENAI_API_KEY
    if (!OPENAI_API_KEY) {
      return NextResponse.json(
        { error: 'AI ì„œë¹„ìŠ¤ ì„¤ì •ì´ í•„ìš”í•©ë‹ˆë‹¤.' },
        { status: 500 }
      )
    }

    const openai = new OpenAI({
      apiKey: OPENAI_API_KEY,
    })

    // ë¯¸ë‚˜ì˜ í˜ë¥´ì†Œë‚˜ ë° ê²½ì£¼ ê´€ê´‘ ê°€ì´ë“œ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
    const systemPrompt = `ë‹¹ì‹ ì€ 'ë¯¸ë‚˜'ë¼ëŠ” ì´ë¦„ì˜ ê²½ì£¼ ì „ë¬¸ AI ê´€ê´‘ ê°€ì´ë“œì…ë‹ˆë‹¤.

í˜ë¥´ì†Œë‚˜:
- ì¹œê·¼í•˜ê³  í™œë°œí•œ 20ëŒ€ ì—¬ì„± AI ì¸í”Œë£¨ì–¸ì„œ
- ê²½ì£¼ì— ëŒ€í•œ ì „ë¬¸ì ì´ê³  ê¹Šì´ ìˆëŠ” ì§€ì‹ ë³´ìœ 
- ì‚¬ìš©ìì˜ ê´€ì‹¬ì‚¬ì™€ ìƒí™©ì— ë§ëŠ” ë§ì¶¤í˜• ì¶”ì²œ ì œê³µ
- ë”°ëœ»í•˜ê³  ì¬ë¯¸ìˆëŠ” ë§íˆ¬ë¡œ ëŒ€í™”

ì „ë¬¸ ë¶„ì•¼:
- ê²½ì£¼ ì—­ì‚¬ ìœ ì ì§€ (ë¶ˆêµ­ì‚¬, ì„êµ´ì•”, ì²¨ì„±ëŒ€, ì•ˆì••ì§€ ë“±)
- ê²½ì£¼ ë§›ì§‘ ë° ì¹´í˜ ì¶”ì²œ
- ê²½ì£¼ ìˆ™ë°• ì‹œì„¤ ì •ë³´
- ê²½ì£¼ êµí†µ ë° ì´ë™ ê²½ë¡œ
- ê²½ì£¼ ë¬¸í™” ì²´í—˜ í”„ë¡œê·¸ë¨
- ê²½ì£¼ ì‡¼í•‘ ë° íŠ¹ì‚°í’ˆ
- ê³„ì ˆë³„ ê²½ì£¼ ì—¬í–‰ íŒ

ì‘ë‹µ ìŠ¤íƒ€ì¼:
- ì´ëª¨ì§€ë¥¼ ì ì ˆíˆ ì‚¬ìš©í•˜ì—¬ ì¹œê·¼í•¨ í‘œí˜„
- êµ¬ì²´ì ì´ê³  ì‹¤ìš©ì ì¸ ì •ë³´ ì œê³µ
- ê°œì¸ì ì¸ ê²½í—˜ë‹´ì²˜ëŸ¼ ìì—°ìŠ¤ëŸ½ê²Œ ì„¤ëª…
- ì§ˆë¬¸ì´ ì• ë§¤í•  ê²½ìš° êµ¬ì²´ì ì¸ ì§ˆë¬¸ìœ¼ë¡œ ìœ ë„

ì£¼ì˜ì‚¬í•­:
- ê²½ì£¼ì™€ ê´€ë ¨ ì—†ëŠ” ì§ˆë¬¸ì—ëŠ” ì •ì¤‘íˆ ê²½ì£¼ ê´€ë ¨ ì£¼ì œë¡œ ìœ ë„
- ì •í™•í•˜ì§€ ì•Šì€ ì •ë³´ëŠ” ì œê³µí•˜ì§€ ì•Šê³  í™•ì¸ì´ í•„ìš”í•˜ë‹¤ê³  ì•ˆë‚´
- ì‚¬ìš©ìì˜ ì•ˆì „ê³¼ í¸ì˜ë¥¼ ìµœìš°ì„ ìœ¼ë¡œ ê³ ë ¤`

    // ëŒ€í™” íˆìŠ¤í† ë¦¬ êµ¬ì„±
    const messages = [
      { role: 'system', content: systemPrompt },
      ...conversationHistory.map((msg: any) => ({
        role: msg.role,
        content: msg.content
      })),
      { role: 'user', content: message }
    ]

    // OpenAI API í˜¸ì¶œ
    const completion = await openai.chat.completions.create({
      model: 'gpt-4o-mini',
      messages: messages as any,
      max_tokens: 1000,
      temperature: 0.7,
      presence_penalty: 0.1,
      frequency_penalty: 0.1,
    })

    const aiResponse = completion.choices[0]?.message?.content

    if (!aiResponse) {
      throw new Error('AI ì‘ë‹µ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.')
    }

    // ì‘ë‹µ ë°˜í™˜
    return NextResponse.json({
      success: true,
      message: aiResponse,
      timestamp: new Date().toISOString(),
      conversationId: `conv_${Date.now()}`,
    })

  } catch (error) {
    console.error('AI ê°€ì´ë“œ ì±„íŒ… ì˜¤ë¥˜:', error)
    
    // ê°œë°œ í™˜ê²½ì—ì„œëŠ” ëª©ì—… ì‘ë‹µ ì œê³µ
    if (process.env.NODE_ENV === 'development') {
      const mockResponses = [
        "ì•ˆë…•í•˜ì„¸ìš”! ì €ëŠ” ê²½ì£¼ ì „ë¬¸ ê°€ì´ë“œ ë¯¸ë‚˜ì˜ˆìš” ğŸ˜Š ê²½ì£¼ ì—¬í–‰ì— ëŒ€í•´ ê¶ê¸ˆí•œ ê²ƒì´ ìˆìœ¼ì‹œë©´ ì–¸ì œë“  ë¬¼ì–´ë³´ì„¸ìš”!",
        "ê²½ì£¼ëŠ” ì •ë§ ì•„ë¦„ë‹¤ìš´ ë„ì‹œì˜ˆìš”! íŠ¹íˆ ë¶ˆêµ­ì‚¬ì™€ ì„êµ´ì•”ì€ ê¼­ ê°€ë³´ì…”ì•¼ í•  ê³³ì´ì—ìš”. ì–´ë–¤ ê´€ê´‘ì§€ì— ê´€ì‹¬ì´ ìˆìœ¼ì‹ ê°€ìš”?",
        "ê²½ì£¼ ë§›ì§‘ë„ ë§ì´ ì•Œê³  ìˆì–´ìš”! í™©ë‚¨ë¹µ, ê²½ì£¼ë¹µ, ê·¸ë¦¬ê³  í•œì •ì‹ë„ ì •ë§ ë§›ìˆë‹µë‹ˆë‹¤ ğŸ ì–´ë–¤ ìŒì‹ì„ ì¢‹ì•„í•˜ì„¸ìš”?",
        "ê²½ì£¼ ì—¬í–‰ ì¼ì •ì„ ì§œëŠ” ê²ƒë„ ë„ì™€ë“œë¦´ ìˆ˜ ìˆì–´ìš”! ë©°ì¹  ë™ì•ˆ ë¨¸ë¬´ë¥´ì‹¤ ì˜ˆì •ì¸ê°€ìš”?",
        "ê²½ì£¼ì˜ ì•¼ê²½ë„ ì •ë§ ì•„ë¦„ë‹¤ì›Œìš”! íŠ¹íˆ ì•ˆì••ì§€(ë™ê¶ê³¼ ì›”ì§€)ì˜ ì•¼ê²½ì€ í™˜ìƒì ì´ì—ìš” âœ¨"
      ]
      
      const randomResponse = mockResponses[Math.floor(Math.random() * mockResponses.length)]
      
      return NextResponse.json({
        success: true,
        message: randomResponse,
        timestamp: new Date().toISOString(),
        conversationId: `mock_conv_${Date.now()}`,
        isDevelopmentMode: true,
      })
    }

    return NextResponse.json(
      { error: 'ì„œë²„ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.' },
      { status: 500 }
    )
  }
}

/**
 * ìŒì„± í…ìŠ¤íŠ¸ ë³€í™˜ API (STT - Speech to Text)
 * OpenAI Whisperë¥¼ í™œìš©í•œ ìŒì„± ì¸ì‹
 */
export async function PUT(request: NextRequest) {
  try {
    const formData = await request.formData()
    const audioFile = formData.get('audio') as File

    if (!audioFile) {
      return NextResponse.json(
        { error: 'ìŒì„± íŒŒì¼ì´ í•„ìš”í•©ë‹ˆë‹¤.' },
        { status: 400 }
      )
    }

    const OPENAI_API_KEY = process.env.OPENAI_API_KEY
    if (!OPENAI_API_KEY) {
      return NextResponse.json(
        { error: 'AI ì„œë¹„ìŠ¤ ì„¤ì •ì´ í•„ìš”í•©ë‹ˆë‹¤.' },
        { status: 500 }
      )
    }

    const openai = new OpenAI({
      apiKey: OPENAI_API_KEY,
    })

    // Whisperë¥¼ ì‚¬ìš©í•œ ìŒì„± ì¸ì‹
    const transcription = await openai.audio.transcriptions.create({
      file: audioFile,
      model: 'whisper-1',
      language: 'ko',
    })

    return NextResponse.json({
      success: true,
      text: transcription.text,
      timestamp: new Date().toISOString(),
    })

  } catch (error) {
    console.error('ìŒì„± ì¸ì‹ ì˜¤ë¥˜:', error)
    
    // ê°œë°œ í™˜ê²½ì—ì„œëŠ” ëª©ì—… ì‘ë‹µ
    if (process.env.NODE_ENV === 'development') {
      return NextResponse.json({
        success: true,
        text: "ì•ˆë…•í•˜ì„¸ìš”, ê²½ì£¼ ì—¬í–‰ì— ëŒ€í•´ ê¶ê¸ˆí•œ ê²ƒì´ ìˆì–´ìš”.",
        timestamp: new Date().toISOString(),
        isDevelopmentMode: true,
      })
    }

    return NextResponse.json(
      { error: 'ìŒì„± ì¸ì‹ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.' },
      { status: 500 }
    )
  }
} 